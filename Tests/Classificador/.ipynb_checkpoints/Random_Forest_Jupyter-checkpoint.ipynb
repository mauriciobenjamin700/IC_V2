{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba91f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  57.14285714285714\n",
      "\n",
      "Matriz de Confusão:  [[0 1 0 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 1 6 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nPrecisão: \",precision_score(y_teste, y_pred))\\nprint(\"\\nRecall: \",recall_score(y_teste, y_pred))\\nprint(\"\\nf1\",f1_score(y_teste, y_pred))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operar_planilha import ler_planilha\n",
    "\n",
    "\"\"\"\n",
    "Matriz de Confusão: É uma tabela que mostra a contagem de verdadeiros positivos, verdadeiros negativos, \n",
    "falsos positivos e falsos negativos. É uma maneira útil de avaliar a precisão do modelo.\n",
    "\"\"\"\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\"\"\"\n",
    "recisão, Recall e F1-score: São métricas que medem a precisão,\n",
    "a capacidade de recuperar e a média harmônica entre precisão e recall, respectivamente.\n",
    "\"\"\"\n",
    "#from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "#criando dataframe com os dados que coletamos e adicionamos na planilha FAMACHA_02\n",
    "df = ler_planilha(\"FAMACHA_03\")\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "#print(df.dtypes)\n",
    "\n",
    "#Filtragem das colunas que usaremos, no caso todos exceto o nome da imagem que não será útil\n",
    "colunas = ['Media_Canal_R','Media_Canal_G','Media_Canal_B','Mediana_Canal_R','Mediana_Canal_G','Mediana_Canal_B','Desvio_Canal_R','Desvio_Canal_G','Desvio_Canal_B']\n",
    "\n",
    "#usaremos x para procurar um padrão nos dados visando encontrar o Grau FAMACHA localizando nesse padrão\n",
    "x = df[colunas]\n",
    "\n",
    "# y é nosso 'target' ou objetivo, logo todos os resultados de x visam encontrar a resposta certa em y\n",
    "y = df['Grau_FAMACHA']\n",
    "\n",
    "#começaremos definindo o que é treino e o que é teste\n",
    "\n",
    "\"\"\"\n",
    "Antes do treino começar, devemos organizar os seguintes parametros e após organizalos o treino começa\n",
    "\n",
    "'test_size' serve para dizer que os dados serão divididos neste caso em \n",
    "70% para treino e 30% para teste\n",
    "\n",
    "'random_state' serve para definir o grau de aleatóriedade durante o treinamento\n",
    "neste caso está zerado, logo sempre treinaremos com 70% dos dados e testaremos 30% dos dados\n",
    "\"\"\"\n",
    "x_treino, x_teste, y_treino,y_teste = train_test_split(x,y,test_size=0.1,random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "Ao instanciarmos nosso modelo temos que levar em conta:\n",
    "'n_estimators' que se refere ao número de interações \n",
    "'n_jobs' Numero de processos ocorrendo em paralelo\n",
    "'random_state' serve para definir o grau de aleatóriedade durante o treinamento\n",
    "neste caso está zerado, logo sempre treinaremos com 70% dos dados e testaremos 30% dos dados\n",
    "\"\"\"\n",
    "\n",
    "modelo = RandomForestClassifier(n_estimators=1000,n_jobs=-1,random_state=0)\n",
    "\n",
    "modelo.fit(x_treino,y_treino)\n",
    "\n",
    "\n",
    "#realizando a predição do modelo com alguns testes\n",
    "y_pred = modelo.predict(x_teste)\n",
    "\n",
    "#verificando a precisão do nosso modelo\n",
    "print('Acurácia: ', accuracy_score(y_teste, y_pred) * 100)\n",
    "\n",
    "print(\"\\nMatriz de Confusão: \", confusion_matrix(y_teste, y_pred))\n",
    "\"\"\"\n",
    "print(\"\\nPrecisão: \",precision_score(y_teste, y_pred))\n",
    "print(\"\\nRecall: \",recall_score(y_teste, y_pred))\n",
    "print(\"\\nf1\",f1_score(y_teste, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40e6bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTestes Usando os seguintes parâmetros\\n\\ntest_size = 0.1\\nn_estimators = 100\\n\\nAcurácio = 39.285714285714285\\n\\ntest_size = 0.2\\nn_estimators = 100\\n\\nAcurácio = 39.285714285714285\\n\\ntest_size = 0.3\\nn_estimators = 100\\n\\nAcurácio = 50.0\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testes Usando os seguintes parâmetros na base de dados FAMACHA_03\n",
    "\n",
    "#TROCANDO APENAS OS teste_size\n",
    "\n",
    "test_size = 0.1\n",
    "n_estimators = 100\n",
    "\n",
    "Acurácio = 50.0\n",
    "###################################\n",
    "test_size = 0.2\n",
    "n_estimators = 100\n",
    "\n",
    "Acurácia = 39.285714285714285\n",
    "################################\n",
    "test_size = 0.3\n",
    "n_estimators = 100\n",
    "\n",
    "Acurácia = 50.0\n",
    "#####################################3\n",
    "\n",
    "#usando n_estimators = 1000\n",
    "\n",
    "test_size = 0.1\n",
    "n_estimators = 1000\n",
    "\n",
    "Acurácia = 57.14285714285714\n",
    "\n",
    "#####################################\n",
    "\n",
    "test_size = 0.2\n",
    "n_estimators = 1000\n",
    "\n",
    "Acurácia = 42.857142857142854\n",
    "\n",
    "##################################333\n",
    "\n",
    "test_size = 0.3\n",
    "n_estimators = 1000\n",
    "\n",
    "Acurácia = 47.61904761904761\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1562933d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (876179129.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Notebook\\AppData\\Local\\Temp\\ipykernel_8080\\876179129.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# teste usando imput de img\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#nome_imagem = str(input(\"Nome da imagem na pasta imagens_2: \"))\n",
    "\n",
    "imagem = cv2.imread(\"imagens_2\\3131_4.jpg\")\n",
    "print(type(imagem)\n",
    "\n",
    "     \n",
    "#imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\"\"\"\n",
    "Pré-processamento: O modelo espera que as imagens de entrada tenham um tamanho e formato específicos. \n",
    "Portanto, você precisa redimensionar e ajustar a imagem para corresponder às dimensões de entrada do modelo. \n",
    "Além disso, é comum normalizar as imagens, dividindo cada pixel pelo valor máximo de pixel (geralmente 255). \n",
    "Aqui está um exemplo:\n",
    "import numpy as np\n",
    "\n",
    "image = image.resize((224, 224))  # ajusta o tamanho da imagem para 224x224\n",
    "image = np.array(image) / 255.0   # normaliza os pixels da imagem\n",
    "image = np.expand_dims(image, axis=0)  # adiciona uma dimensão para acomodar o número de lotes\n",
    "\n",
    "\n",
    "\n",
    "imagem = imagem.resize((224,224))\n",
    "imagem = np.array(imagem) / 255\n",
    "imagem = np.expand_dims(imagem, axis=0)\n",
    "\n",
    "    \n",
    "#testando a imagem com o modelo que criamos\n",
    "\n",
    "resltado = modelo.predict(imagem)\n",
    "\n",
    "classes = [\"Grau_1\", \"Grau_2\", \"Grau_3\", \"Grau_4\", \"Grau_5\"]\n",
    "\n",
    "predicted_class = np.argmax(resultado, axis=1)\n",
    "predicted_class_name = classes[predicted_class[0]]\n",
    "\n",
    "veredito = predicted_class_name\n",
    "\n",
    "print(f\"Provavelmente a imagem é de {veredito}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e300ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
